{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os\n",
    "from string import printable\n",
    "from sklearn import model_selection\n",
    "\n",
    "#import gensim\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, model_from_json, load_model\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda, Flatten\n",
    "from keras.layers import Input, ELU, LSTM, Embedding, Convolution2D, MaxPooling2D, \\\n",
    "BatchNormalization, Convolution1D, MaxPooling1D, concatenate\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>isMalicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170781</th>\n",
       "      <td>ableo.ru/LIF.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181070</th>\n",
       "      <td>amazon.com/Seven-Little-Foys-Bob-Hope/dp/B000U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89886</th>\n",
       "      <td>f1carsetup.com/index.php/forum/16-canadian-gra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209167</th>\n",
       "      <td>city-data.com/los-angeles-county/V/Victory-Bou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407356</th>\n",
       "      <td>sadek-music.com/x66g7y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167149</th>\n",
       "      <td>123people.ca/s/louise+galipeau</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372891</th>\n",
       "      <td>yellowpages.com/kansas-city-mo/dentists</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273982</th>\n",
       "      <td>landlpardey.com/us-sailboat-show-featured-on-t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238335</th>\n",
       "      <td>fanbase.com/Frank-Solich</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340770</th>\n",
       "      <td>spokeo.com/Jeanne+Caldwell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247221</th>\n",
       "      <td>frumforum.com/conrad-black-relives-his-trial</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393308</th>\n",
       "      <td>6i3cb6owitcouepv.mywa2pay.com/img/flags/es.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49599</th>\n",
       "      <td>artillery-museum.ru/en/collection.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30674</th>\n",
       "      <td>newsloja.vitaliteestetica.com.br/users/sign_in</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354610</th>\n",
       "      <td>travelodge.co.uk/hotels/info?hotelId=415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94135</th>\n",
       "      <td>francisscarpaleggia.liberal.ca/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244334</th>\n",
       "      <td>fnb-palm.com/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319254</th>\n",
       "      <td>poemhunter.com/poem/the-ten-lepers/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392178</th>\n",
       "      <td>imanaging.info/img1.php?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11973</th>\n",
       "      <td>fb-2016.atwebpages.com/Fb-Safety_Centre/others...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16586</th>\n",
       "      <td>ecreatify.com/cho/express/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253616</th>\n",
       "      <td>hamilton.ca/YourElectedOfficials/WardCouncillo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113595</th>\n",
       "      <td>lostmementos.blogspot.com/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204492</th>\n",
       "      <td>cbs.com/primetime/big_bang_theory/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229780</th>\n",
       "      <td>facebook.com/Catherine.Asaro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  isMalicious\n",
       "170781                                  ableo.ru/LIF.html            0\n",
       "181070  amazon.com/Seven-Little-Foys-Bob-Hope/dp/B000U...            0\n",
       "89886   f1carsetup.com/index.php/forum/16-canadian-gra...            0\n",
       "209167  city-data.com/los-angeles-county/V/Victory-Bou...            0\n",
       "407356                             sadek-music.com/x66g7y            1\n",
       "167149                     123people.ca/s/louise+galipeau            0\n",
       "372891            yellowpages.com/kansas-city-mo/dentists            0\n",
       "273982  landlpardey.com/us-sailboat-show-featured-on-t...            0\n",
       "238335                           fanbase.com/Frank-Solich            0\n",
       "340770                         spokeo.com/Jeanne+Caldwell            0\n",
       "247221       frumforum.com/conrad-black-relives-his-trial            0\n",
       "393308     6i3cb6owitcouepv.mywa2pay.com/img/flags/es.png            1\n",
       "49599              artillery-museum.ru/en/collection.html            0\n",
       "30674      newsloja.vitaliteestetica.com.br/users/sign_in            1\n",
       "354610           travelodge.co.uk/hotels/info?hotelId=415            0\n",
       "94135                     francisscarpaleggia.liberal.ca/            0\n",
       "244334                                      fnb-palm.com/            0\n",
       "319254                poemhunter.com/poem/the-ten-lepers/            0\n",
       "392178                           imanaging.info/img1.php?            1\n",
       "11973   fb-2016.atwebpages.com/Fb-Safety_Centre/others...            1\n",
       "16586                          ecreatify.com/cho/express/            1\n",
       "253616  hamilton.ca/YourElectedOfficials/WardCouncillo...            0\n",
       "113595                         lostmementos.blogspot.com/            0\n",
       "204492                 cbs.com/primetime/big_bang_theory/            0\n",
       "229780                       facebook.com/Catherine.Asaro            0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load data URL\n",
    "\n",
    "DATA_HOME = 'C:/Users/arnav/'\n",
    "df = pd.read_csv(DATA_HOME + 'urldataDNN.csv')\n",
    "df.sample(n=25).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions of X:  (420464, 75) Vector dimension of target:  (420464,)\n"
     ]
    }
   ],
   "source": [
    "# Initial Data Preparation URL\n",
    "\n",
    "# Step 1: Convert raw URL string in list of lists where characters that are contained in \"printable\" are stored encoded as integer \n",
    "url_int_tokens = [[printable.index(x) + 1 for x in url if x in printable] for url in df.url]\n",
    "\n",
    "# Step 2: Cut URL string at max_len or pad with zeros if shorter\n",
    "max_len=75\n",
    "X = sequence.pad_sequences(url_int_tokens, maxlen=max_len)\n",
    " \n",
    "# Step 3: Extract labels form df to numpy array\n",
    "target = np.array(df.isMalicious)\n",
    "\n",
    "print('Matrix dimensions of X: ', X.shape, 'Vector dimension of target: ', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Cross-Validation: Split the data set into training and test data\n",
    "X_train, X_test, target_train, target_test = model_selection.train_test_split(X, target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL get layer dimensions for any model!\n",
    "def print_layers_dims(model):\n",
    "    l_layers = model.layers\n",
    "    # Note None is ALWAYS batch_size\n",
    "    for i in range(len(l_layers)):\n",
    "        print(l_layers[i])\n",
    "        print('Input Shape: ', l_layers[i].input_shape, 'Output Shape: ', l_layers[i].output_shape)\n",
    "\n",
    "# GENERAL save model to disk function!\n",
    "def save_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    #have h5py installed\n",
    "    if Path(fileModelJSON).is_file():\n",
    "        os.remove(fileModelJSON)\n",
    "    json_string = model.to_json()\n",
    "    with open(fileModelJSON,'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    if Path(fileWeights).is_file():\n",
    "        os.remove(fileWeights)\n",
    "    model.save_weights(fileWeights)\n",
    "    \n",
    "\n",
    "# GENERAL load model from disk function!\n",
    "def load_model(fileModelJSON,fileWeights):\n",
    "    #print(\"Saving model to disk: \",fileModelJSON,\"and\",fileWeights)\n",
    "    with open(fileModelJSON, 'r') as f:\n",
    "         model_json = json.load(f)\n",
    "         model = model_from_json(model_json)\n",
    "    \n",
    "    model.load_weights(fileWeights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deep Learning model Definition --- C --- (1D Convolutions and Fully Connected Layers)\n",
    "\n",
    "def conv_fully(max_len=75, emb_dim=32, max_vocab_len=100, W_reg=regularizers.l2(1e-4)):\n",
    "    # Input\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    # Embedding layer\n",
    "    emb = Embedding(input_dim=max_vocab_len, output_dim=emb_dim, input_length=max_len,\n",
    "                W_regularizer=W_reg)(main_input) \n",
    "    emb = Dropout(0.25)(emb)\n",
    "\n",
    "    \n",
    "    def sum_1d(X):\n",
    "        return K.sum(X, axis=1)\n",
    "    \n",
    "    def get_conv_layer(emb, kernel_size=5, filters=256):\n",
    "        # Conv layer\n",
    "        conv = Convolution1D(kernel_size=kernel_size, filters=filters, \\\n",
    "                     border_mode='same')(emb)\n",
    "        conv = ELU()(conv)\n",
    "\n",
    "        conv = Lambda(sum_1d, output_shape=(filters,))(conv)\n",
    "        #conv = BatchNormalization(mode=0)(conv)\n",
    "        conv = Dropout(0.5)(conv)\n",
    "        return conv\n",
    "        \n",
    "    # Multiple Conv Layers\n",
    "    \n",
    "    # calling custom conv function from above\n",
    "    conv1 = get_conv_layer(emb, kernel_size=2, filters=256)\n",
    "    conv2 = get_conv_layer(emb, kernel_size=3, filters=256)\n",
    "    conv3 = get_conv_layer(emb, kernel_size=4, filters=256)\n",
    "    conv4 = get_conv_layer(emb, kernel_size=5, filters=256)\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    merged = concatenate([conv1,conv2,conv3,conv4], axis=1)\n",
    "\n",
    "    hidden1 = Dense(1024)(merged)\n",
    "    hidden1 = ELU()(hidden1)\n",
    "    hidden1 = BatchNormalization(mode=0)(hidden1)\n",
    "    hidden1 = Dropout(0.5)(hidden1)\n",
    "\n",
    "    hidden2 = Dense(1024)(hidden1)\n",
    "    hidden2 = ELU()(hidden2)\n",
    "    hidden2 = BatchNormalization(mode=0)(hidden2)\n",
    "    hidden2 = Dropout(0.5)(hidden2)\n",
    "    \n",
    "    # Output layer (last fully connected layer)\n",
    "    output = Dense(1, activation='sigmoid', name='output')(hidden2)\n",
    "\n",
    "    # Compile model and define optimizer\n",
    "    model = Model(input=[main_input], output=[output])\n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arnav\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\arnav\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\arnav\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "315348/315348 [==============================] - 920s 3ms/step - loss: 0.3996 - acc: 0.8344\n",
      "Epoch 2/5\n",
      "315348/315348 [==============================] - 918s 3ms/step - loss: 0.3011 - acc: 0.8798\n",
      "Epoch 3/5\n",
      "315348/315348 [==============================] - 911s 3ms/step - loss: 0.2716 - acc: 0.8946\n",
      "Epoch 4/5\n",
      "315348/315348 [==============================] - 797s 3ms/step - loss: 0.2541 - acc: 0.9028\n",
      "Epoch 5/5\n",
      "315348/315348 [==============================] - 678s 2ms/step - loss: 0.2456 - acc: 0.9056\n",
      "105116/105116 [==============================] - 57s 540us/step\n",
      "\n",
      "Final Cross-Validation Accuracy 0.9183378362951407 \n",
      "\n",
      "<keras.engine.input_layer.InputLayer object at 0x000002AC7FECDEB8>\n",
      "Input Shape:  (None, 75) Output Shape:  (None, 75)\n",
      "<keras.layers.embeddings.Embedding object at 0x000002AC6F74F940>\n",
      "Input Shape:  (None, 75) Output Shape:  (None, 75, 32)\n",
      "<keras.layers.core.Dropout object at 0x000002AC679C44A8>\n",
      "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 32)\n",
      "<keras.layers.convolutional.Conv1D object at 0x000002AC679C45C0>\n",
      "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 256)\n",
      "<keras.layers.convolutional.Conv1D object at 0x000002AC00514358>\n",
      "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 256)\n",
      "<keras.layers.convolutional.Conv1D object at 0x000002AC00427DA0>\n",
      "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 256)\n",
      "<keras.layers.convolutional.Conv1D object at 0x000002AC004632E8>\n",
      "Input Shape:  (None, 75, 32) Output Shape:  (None, 75, 256)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000002AC003675F8>\n",
      "Input Shape:  (None, 75, 256) Output Shape:  (None, 75, 256)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000002AC003BC940>\n",
      "Input Shape:  (None, 75, 256) Output Shape:  (None, 75, 256)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000002AC00427DD8>\n",
      "Input Shape:  (None, 75, 256) Output Shape:  (None, 75, 256)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000002AC004AAB70>\n",
      "Input Shape:  (None, 75, 256) Output Shape:  (None, 75, 256)\n",
      "<keras.layers.core.Lambda object at 0x000002AC6F74FBA8>\n",
      "Input Shape:  (None, 75, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Lambda object at 0x000002AC003DEA58>\n",
      "Input Shape:  (None, 75, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Lambda object at 0x000002AC00463978>\n",
      "Input Shape:  (None, 75, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Lambda object at 0x000002AC00537C50>\n",
      "Input Shape:  (None, 75, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Dropout object at 0x000002AC00514EB8>\n",
      "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Dropout object at 0x000002AC003DEAC8>\n",
      "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Dropout object at 0x000002AC00463160>\n",
      "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.core.Dropout object at 0x000002AC0055DA58>\n",
      "Input Shape:  (None, 256) Output Shape:  (None, 256)\n",
      "<keras.layers.merge.Concatenate object at 0x000002AC0055D208>\n",
      "Input Shape:  [(None, 256), (None, 256), (None, 256), (None, 256)] Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dense object at 0x000002AC0057EE10>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000002AC005BE2B0>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002AC005BE518>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dropout object at 0x000002AC005BEFD0>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dense object at 0x000002AC0062DFD0>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.advanced_activations.ELU object at 0x000002AC006773C8>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000002AC00677E48>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dropout object at 0x000002AC00766E80>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1024)\n",
      "<keras.layers.core.Dense object at 0x000002AC00793748>\n",
      "Input Shape:  (None, 1024) Output Shape:  (None, 1)\n"
     ]
    }
   ],
   "source": [
    "# Fit model and Cross-Validation, ARCHITECTURE 3 CONV + FULLY CONNECTED\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "model = conv_fully()\n",
    "model.fit(X_train, target_train, epochs=epochs, batch_size=batch_size)\n",
    "loss, accuracy = model.evaluate(X_test, target_test, verbose=1)\n",
    "\n",
    "print('\\nFinal Cross-Validation Accuracy', accuracy, '\\n')\n",
    "print_layers_dims(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities of target predictions\n",
    "target_proba = model.predict(X_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02589654],\n",
       "       [0.0124423 ],\n",
       "       [0.00492469],\n",
       "       [0.00351022],\n",
       "       [0.00018272],\n",
       "       [0.05806975],\n",
       "       [0.02408956],\n",
       "       [0.00154053],\n",
       "       [0.01838404],\n",
       "       [0.00348988]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_proba[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deeplearning_1DConv\"\n",
    "save_model(DATA_HOME + model_name + \".json\", DATA_HOME + model_name + \".h5\")\n",
    "model = load_model(DATA_HOME + model_name + \".json\", DATA_HOME + model_name + \".h5\")\n",
    "#print_layers_dims(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get for example word2vec embedding weight matix\n",
    "l_layers = model.layers\n",
    "weights = l_layers[1].get_weights()\n",
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url_mal = \"naureen.net/etisalat.ae/index2.php\"\n",
    "test_url_benign = \"sixt.com/php/reservation?language=en_US\"\n",
    "\n",
    "url = test_url_benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert raw URL string in list of lists where characters that are contained in \"printable\" are stored encoded as integer \n",
    "url_int_tokens = [[printable.index(x) + 1 for x in url if x in printable]]\n",
    "\n",
    "# Step 2: Cut URL string at max_len or pad with zeros if shorter\n",
    "max_len=75\n",
    "X = sequence.pad_sequences(url_int_tokens, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test URL: sixt.com/php/reservation?language=en_US is benign\n"
     ]
    }
   ],
   "source": [
    "target_proba = model.predict(X, batch_size=1)\n",
    "def print_result(proba):\n",
    "    if proba > 0.5:\n",
    "        return \"malicious\"\n",
    "    else:\n",
    "        return \"benign\"\n",
    "print(\"Test URL:\", url, \"is\", print_result(target_proba[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
